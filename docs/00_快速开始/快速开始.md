# 快速开始

---

## TL;DR - 30秒启动

> **已完成环境配置？** 直接运行：

```bash
source ~/.bashrc
ros2 launch robot_bringup bringup.launch.py
```

**预期效果**：
- 机器人眼睛显示待机动画
- 终端输出 `[motor_node]: Serial connected`
- 如已启用语音：机器人说"你好，我是 Aura"

首次配置请继续阅读下文。

---

## 认识 Aura Alpha

**Aura Alpha** 是一款基于 ROS2 的智能球形机器人开发平台，专为 AI 应用开发和机器人教育设计。

### 核心能力

| 能力 | 说明 |
|------|------|
| **视觉感知** | 基于 RDK X5 BPU 加速的实时人体检测与跟踪 |
| **语音交互** | 支持火山引擎、百度等云端大模型，实现自然对话 |
| **自主运动** | 双轮差速驱动，支持跟随、避障等行为 |
| **表情显示** | 圆形屏幕显示动态表情，增强交互体验 |

### 硬件架构

```
┌─────────────────────────────────────────────┐
│              Aura Alpha                     │
├─────────────────────────────────────────────┤
│  计算平台: RDK X5 (10 TOPS BPU)             │
│  传感器:   MIPI 摄像头 / 麦克风阵列         │
│  执行器:   双轮电机 / 圆形显示屏 / 扬声器   │
│  通信:     Wi-Fi / USB 串口                 │
└─────────────────────────────────────────────┘
```

### 软件架构

基于 ROS2 Humble 的模块化设计：

- **驱动层**：电机控制 (`motor_node`)、音频采集/播放 (`audio_duplex_node`)
- **感知层**：人体检测 (`mono2d_body_detection`)、人体跟踪 (`body_tracking`)
- **应用层**：云端语音 (`cloud_realtime_node`)、表情显示 (`display_node`)
- **启动层**：统一入口 (`robot_bringup`)，通过配置文件控制功能开关

详细规格请参考 [硬件规格](../01_硬件规格/硬件规格.md) 和 [技术原理](../02_技术原理/技术原理.md)。

---

## 1. 环境准备

### 1.1 系统要求

| 项目 | 要求 |
|------|------|
| 硬件平台 | RDK X5 |
| 操作系统 | Ubuntu 22.04 |
| ROS2 版本 | Humble (TogetheROS) |
| Python | 3.10+ |
| 网络 | 语音功能需联网 |

### 1.2 首次配置（仅执行一次）

#### 步骤 1：安装 TogetheROS

```bash
sudo apt update && sudo apt upgrade -y
sudo apt install tros-humble-ros-base tros-humble-dnn-node tros-humble-ai-msgs -y
```

#### 步骤 2：获取源代码

```bash
# 克隆仓库（请向团队获取实际仓库地址）
git clone https://gitee.com/aura-robotics/aura-alpha.git ~/robot_ws

cd ~/robot_ws/workspace
```

#### 步骤 3：安装依赖

```bash
# Python 依赖
pip3 install -r ~/robot_ws/requirements.txt

# ROS2 依赖
rosdep install --from-paths src --ignore-src -r -y
```

#### 步骤 4：编译工作空间（两阶段）

> **为什么分两阶段？**
> 感知包（`mono2d_body_detection`、`body_tracking`）使用 RDK X5 的 BPU 加速，需要指定平台参数 `-DPLATFORM_X5=ON`。其他包无此依赖，可直接编译。

```bash
# 加载 ROS2 环境
source /opt/tros/humble/setup.bash

# 阶段 1：编译基础包（驱动、应用）
colcon build --packages-skip mono2d_body_detection body_tracking

# 阶段 2：编译感知包（指定 RDK X5 平台）
colcon build --packages-select mono2d_body_detection body_tracking \
    --cmake-args -DPLATFORM_X5=ON
```

#### 步骤 5：配置环境变量

将以下内容添加到 `~/.bashrc`：

```bash
# ROS2 & 工作空间
source /opt/tros/humble/setup.bash
source ~/robot_ws/workspace/install/setup.bash

# 相机类型：mipi（内置）或 usb（外接）
export CAM_TYPE=mipi
```

使配置生效：

```bash
source ~/.bashrc
```

#### 步骤 6：添加串口权限

电机通过 USB 串口通信，需要 dialout 组权限：

```bash
sudo usermod -aG dialout $USER
```

> **必须重新登录或重启**，权限才会生效。
> 快速验证：执行 `groups` 命令，输出应包含 `dialout`。

---

## 2. 启动路径选择

根据您的需求选择合适的启动路径：

| 路径 | 适用场景 | 网络要求 | API 要求 |
|------|---------|---------|---------|
| [2.1 电机验证](#21-最快路径电机验证) | 首次验证硬件是否正常 | 无 | 无 |
| [2.2 视觉跟随](#22-视觉跟随路径) | 测试感知和运动控制 | 无 | 无 |
| [2.3 语音交互](#23-语音交互路径) | 测试语音对话功能 | 需联网 | 需配置 |
| [2.4 完整功能](#24-完整功能路径推荐) | 正常使用 | 需联网 | 需配置 |

### 2.1 最快路径：电机验证

**目标**：验证电机和串口通信正常

```bash
# 终端 1：启动电机节点
ros2 run motor_node motor_node
```

**预期输出**：
```
[INFO] [motor_node]: Serial connected to /dev/ttyUSB0
[INFO] [motor_node]: Motor node ready
```

```bash
# 终端 2：发送控制指令
ros2 topic pub /cmd_vel geometry_msgs/Twist "{linear: {x: 0.1}}" -1
```

**预期效果**：机器人缓慢前进一下

```bash
# 停止
ros2 topic pub /cmd_vel geometry_msgs/Twist "{}" -1
```

> **常见问题**：
> - `Permission denied: /dev/ttyUSB0` → 参考 [步骤 6](#步骤-6添加串口权限)
> - `Serial not found` → 检查 USB 线是否连接

### 2.2 视觉跟随路径

**目标**：机器人自动跟随检测到的人体

**前提**：已安装并连接 MIPI 或 USB 摄像头

#### 步骤 1：启用人体跟随

编辑 `~/robot_ws/workspace/src/bringup/robot_bringup/config/settings.yaml`：

```yaml
settings:
  enable_body_following: true   # 启用跟随
  enable_voice: false           # 语音关闭（无需网络）
```

#### 步骤 2：启动系统

```bash
ros2 launch robot_bringup bringup.launch.py
```

**预期效果**：
- 摄像头前站一个人
- 机器人转向并靠近该人
- 人移动时机器人跟随

#### 步骤 3：验证检测输出

```bash
# 另开终端，查看人体检测结果
ros2 topic echo /hobot_mono2d_body_detection
```

### 2.3 语音交互路径

**目标**：与机器人进行语音对话

**前提**：网络连接正常 + API 密钥已配置（参考 [3.3 节](#33-api-密钥配置详解)）

#### 步骤 1：启用语音功能

编辑 `~/robot_ws/workspace/src/bringup/robot_bringup/config/settings.yaml`：

```yaml
settings:
  enable_body_following: false  # 跟随关闭
  enable_voice: true            # 启用语音
```

#### 步骤 2：启动系统

```bash
ros2 launch robot_bringup bringup.launch.py enable_perception:=false
```

> `enable_perception:=false` 跳过感知层启动，加快启动速度。

**预期效果**：
- 终端输出 `[cloud_realtime_node]: WebSocket connected`
- 机器人说出欢迎语
- 对机器人说话，它会回应

### 2.4 完整功能路径（推荐）

**目标**：同时启用视觉跟随 + 语音交互

**前提**：网络连接正常 + API 密钥已配置

#### 步骤 1：配置功能开关

编辑 `~/robot_ws/workspace/src/bringup/robot_bringup/config/settings.yaml`：

```yaml
settings:
  enable_body_following: true   # 启用跟随
  enable_voice: true            # 启用语音
```

#### 步骤 2：启动系统

```bash
ros2 launch robot_bringup bringup.launch.py
```

**预期效果**：
- 眼睛显示待机动画 → 视频加载完成
- 机器人说"你好" → 语音连接成功
- 站在机器人前 → 开始跟随
- 说"你好 Aura" → 语音对话

**启动顺序（自动）**：
1. `display_node` 加载视频，发布 `/display/ready`
2. `cloud_realtime_node` 连接云端，发布 `/cloud_realtime/ready`
3. `body_tracking` 启动感知

---

## 3. 功能配置

### 3.1 功能开关 (settings.yaml)

配置文件位置：`~/robot_ws/workspace/src/bringup/robot_bringup/config/settings.yaml`

```yaml
settings:
  # 人体跟随
  #   true:  机器人自动跟随检测到的人体
  #   false: 禁用跟随（body_tracking 输出到 /follow_cmd_vel，不影响 /cmd_vel）
  enable_body_following: false

  # 语音交互
  #   true:  启动云端语音 AI，机器人可以听和说
  #   false: 禁用语音功能，适合调试或无网络环境
  enable_voice: false
```

> 修改后重启 `bringup.launch.py` 即可生效，无需重新编译。

### 3.2 语音服务商切换

配置文件位置：`~/robot_ws/workspace/src/apps/cloud_realtime_node/config/config.yaml`

```yaml
cloud_realtime:
  ros__parameters:
    # 可选值: volcano_engine, baidu, openai, gemini
    provider: "volcano_engine"
```

| 服务商 | 优势 | 状态 |
|-------|------|------|
| `volcano_engine` | 国内访问快、中文效果好 | 可用 |
| `baidu` | 国内访问快、免费额度 | 可用 |
| `openai` | 英文效果佳 | 计划中 |
| `gemini` | 多模态支持 | 计划中 |

### 3.3 API 密钥配置详解

配置文件位置：`~/robot_ws/workspace/src/apps/cloud_realtime_node/config/config.yaml`

#### 火山引擎（豆包）

1. **注册账号**：访问 [火山引擎控制台](https://console.volcengine.com/)

2. **开通服务**：
   - 进入「语音技术」→「实时语音对话」
   - 开通服务并创建应用

3. **获取凭证**：
   - 在应用详情页找到 `App ID`、`Access Key`、`App Key`

4. **填入配置**：

```yaml
volcano_engine:
  app_id: "你的App ID"           # 例如: "2298646415"
  access_key: "你的Access Key"   # 例如: "NhBlJ8AQ..."
  app_key: "你的App Key"         # 例如: "PlgvMymc..."
  resource_id: "volc.speech.dialog"
  base_url: "wss://openspeech.bytedance.com/api/v3/realtime/dialogue"
  bot_name: "AI Assistant"
  tts_speaker: "zh_male_yunzhou_jupiter_bigtts"
```

#### 百度（文心一言）

1. **注册账号**：访问 [百度智能云控制台](https://console.bce.baidu.com/)

2. **开通服务**：
   - 进入「千帆大模型平台」
   - 开通 ERNIE 模型 API

3. **创建应用**：
   - 创建应用获取 `API Key` 和 `Secret Key`

4. **填入配置**：

```yaml
baidu:
  app_id: "你的App ID"
  api_key: "你的API Key"
  secret_key: "你的Secret Key"
  model: "ERNIE-4.0-8K"    # 可选: ERNIE-4.0-8K, ERNIE-3.5-8K
```

> **验证配置**：启动后查看日志，正确配置会输出 `WebSocket connected`，
> 错误配置会输出 `Invalid access_key` 或 `Invalid api_key`。

---

## 4. 第一个控制程序

### 4.1 最简示例：命令行控制

无需编写代码，直接通过 `ros2 topic pub` 控制：

```bash
# 前进 (0.2 m/s)
ros2 topic pub /cmd_vel geometry_msgs/Twist "{linear: {x: 0.2}}" -1

# 后退
ros2 topic pub /cmd_vel geometry_msgs/Twist "{linear: {x: -0.2}}" -1

# 左转
ros2 topic pub /cmd_vel geometry_msgs/Twist "{angular: {z: 0.3}}" -1

# 右转
ros2 topic pub /cmd_vel geometry_msgs/Twist "{angular: {z: -0.3}}" -1

# 停止
ros2 topic pub /cmd_vel geometry_msgs/Twist "{}" -1
```

### 4.2 Python 示例：让机器人画个圆

创建 `draw_circle.py`：

```python
#!/usr/bin/env python3
"""让机器人画一个直径约 0.5m 的圆"""

import rclpy
from rclpy.node import Node
from geometry_msgs.msg import Twist
import math


class DrawCircle(Node):
    def __init__(self):
        super().__init__('draw_circle')
        self.pub = self.create_publisher(Twist, '/cmd_vel', 10)
        self.get_logger().info('开始画圆...')

        # 圆周运动参数
        self.linear_speed = 0.15   # m/s
        self.radius = 0.25         # m
        self.angular_speed = self.linear_speed / self.radius

        # 计算完成一圈所需时间
        self.duration = 2 * math.pi / self.angular_speed
        self.start_time = self.get_clock().now()

        # 50Hz 控制频率
        self.timer = self.create_timer(0.02, self.control_loop)

    def control_loop(self):
        elapsed = (self.get_clock().now() - self.start_time).nanoseconds / 1e9

        if elapsed < self.duration:
            msg = Twist()
            msg.linear.x = self.linear_speed
            msg.angular.z = self.angular_speed
            self.pub.publish(msg)
        else:
            # 停止
            self.pub.publish(Twist())
            self.get_logger().info('画圆完成！')
            self.timer.cancel()
            raise SystemExit


def main():
    rclpy.init()
    node = DrawCircle()
    try:
        rclpy.spin(node)
    except SystemExit:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
```

运行：

```bash
# 确保电机节点已启动
ros2 run motor_node motor_node &

# 运行画圆程序
python3 draw_circle.py
```

**预期效果**：机器人沿圆形轨迹移动一圈后停止。

### 4.3 进阶示例

更多示例请参考：[二次开发场景示例](../05_二次开发场景示例/二次开发场景示例.md)

---

## 5. 验证与调试

### 5.1 系统状态检查

```bash
# 查看所有运行中的节点
ros2 node list

# 预期输出（完整功能模式）：
# /motor_node
# /audio_duplex_node
# /cloud_realtime_node
# /display_node
# /body_tracking
# /mono2d_body_detection
```

```bash
# 查看关键话题
ros2 topic list | grep -E "(cmd_vel|motor|audio|ai)"

# 监控电机连接状态
ros2 topic echo /motor/connected --once

# 监控电池状态
ros2 topic echo /battery_state --once
```

### 5.2 常见启动问题速查表

| 错误信息 | 原因 | 解决方案 |
|---------|------|---------|
| `Package 'robot_bringup' not found` | 未加载工作空间 | `source ~/robot_ws/workspace/install/setup.bash` |
| `Permission denied: /dev/ttyUSB0` | 无串口权限 | `sudo usermod -aG dialout $USER` 后重新登录 |
| `Serial not found` | USB 未连接或设备号不对 | `ls /dev/ttyUSB*` 确认设备，修改 `config.yaml` |
| `WebSocket connection failed` | 网络不通或 API 错误 | `ping www.baidu.com`；检查 API 密钥 |
| `Invalid access_key` | 火山引擎密钥错误 | 检查 `config.yaml` 中的凭证 |
| `Invalid api_key` | 百度密钥错误 | 检查 `config.yaml` 中的凭证 |
| `Model inference failed: platform mismatch` | 编译时未指定平台 | 重新编译：`colcon build --cmake-args -DPLATFORM_X5=ON` |
| `Timeout waiting for /display/ready` | 显示节点未正常启动 | 检查视频文件是否存在 |

### 5.3 快速故障定位

```bash
# 方法 1：查看详细日志
ros2 launch robot_bringup bringup.launch.py --log-level debug

# 方法 2：单独启动问题节点
ros2 run motor_node motor_node --ros-args --log-level debug
ros2 run display_node display_node --ros-args --log-level debug

# 方法 3：检查话题是否有数据
ros2 topic hz /cmd_vel        # 查看发布频率
ros2 topic echo /cmd_vel      # 查看具体内容

# 方法 4：检查节点间连接
ros2 node info /motor_node    # 查看订阅和发布
```

---

## 附录

### A. 开箱清单

请在开始前核对包装盒内的组件：

| 组件 | 数量 | 说明 |
|------|------|------|
| Aura Alpha 主机 | 1 | 含 RDK X5 计算单元 |
| 专用充电线 (Type-C) | 1 | 用于充电和调试 |
| 开发者激活卡 | 1 | 包含激活密钥 |

> 请妥善保管开发者激活卡，首次配置时需要使用卡片上的专属密钥。

### B. 核心话题参考

| 话题 | 类型 | 说明 |
|------|------|------|
| `/cmd_vel` | `geometry_msgs/Twist` | 运动控制指令 |
| `/motor/connected` | `std_msgs/Bool` | 电机连接状态 |
| `/battery_state` | `sensor_msgs/BatteryState` | 电池状态 |
| `/imu/data` | `sensor_msgs/Imu` | 陀螺仪数据 |
| `/audio_data` | `std_msgs/Int16MultiArray` | 麦克风音频 |
| `/audio_playback` | `std_msgs/Int16MultiArray` | 扬声器音频 |
| `/ai/state` | `std_msgs/String` | AI 状态 (idle/listening/speaking) |
| `/hobot_mono2d_body_detection` | `ai_msgs/PerceptionTargets` | 人体检测结果 |

### C. 下一步学习路径

1. **了解硬件规格** → [硬件规格](../01_硬件规格/硬件规格.md)
2. **深入技术原理** → [技术原理](../02_技术原理/技术原理.md)
3. **查阅 API 手册** → [API 参考手册](../04_API_参考手册/API_参考手册.md)
4. **尝试开发示例** → [二次开发场景示例](../05_二次开发场景示例/二次开发场景示例.md)
5. **遇到问题** → [常见问题与支持](../06_常见问题与支持/常见问题与支持.md)
